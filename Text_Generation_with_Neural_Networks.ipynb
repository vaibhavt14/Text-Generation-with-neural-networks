{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "colab": {
      "name": "Text-Generation-with-Neural-Networks.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m4ceGp4wl8vQ",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "# Text Generation with Neural Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XVwMdkIul8vR",
        "colab_type": "text"
      },
      "source": [
        "## Functions for Processing Text\n",
        "\n",
        "### Reading in files as a string text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "praIXELSl8vS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_file(filepath):\n",
        "    \n",
        "    with open(filepath) as f:\n",
        "        str_text = f.read()\n",
        "    \n",
        "    return str_text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SuecBbpXl8vX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "read_file('moby_dick_four_chapters.txt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "MQrm-41yl8vb",
        "colab_type": "text"
      },
      "source": [
        "### Tokenize and Clean Text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ljCnsjx6l8vd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import spacy\n",
        "nlp = spacy.load('en',disable=['parser', 'tagger','ner'])\n",
        "\n",
        "nlp.max_length = 1198623"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CtO2oxMKl8vh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def separate_punc(doc_text):\n",
        "    return [token.text.lower() for token in nlp(doc_text) if token.text not in '\\n\\n \\n\\n\\n!\"-#$%&()--.*+,-/:;<=>?@[\\\\]^_`{|}~\\t\\n ']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iava_DPjl8vl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "d = read_file('melville-moby_dick.txt')\n",
        "tokens = separate_punc(d)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZZWApuXl8vo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokens"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LDYYioCll8vs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(tokens)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HWQ2n4abl8vz",
        "colab_type": "text"
      },
      "source": [
        "## Create Sequences of Tokens"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9pdw_Q1Jl8v0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# organize into sequences of tokens\n",
        "train_len = 25+1 # 50 training words , then one target word\n",
        "\n",
        "# Empty list of sequences\n",
        "text_sequences = []\n",
        "\n",
        "for i in range(train_len, len(tokens)):\n",
        "    \n",
        "    # Grab train_len# amount of characters\n",
        "    seq = tokens[i-train_len:i]\n",
        "    \n",
        "    # Add to list of sequences\n",
        "    text_sequences.append(seq)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "46yAM5T_l8v3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "' '.join(text_sequences[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KIEysN7Tl8v8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "' '.join(text_sequences[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K4sEAJcsl8wB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "' '.join(text_sequences[2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8JPGUwVJl8wE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(text_sequences)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xAlQfK3Dl8wH",
        "colab_type": "text"
      },
      "source": [
        "# Keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "buOg7iTJl8wI",
        "colab_type": "text"
      },
      "source": [
        "### Keras Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "IwBr_dhql8wJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "o4VYCTrtl8wM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# integer encode sequences of words\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(text_sequences)\n",
        "sequences = tokenizer.texts_to_sequences(text_sequences)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "_V9TVYmbl8wP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sequences[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "aoh9iWVGl8wT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer.index_word"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "i7HKtiBxl8wW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in sequences[0]:\n",
        "    print(f'{i} : {tokenizer.index_word[i]}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "xXw3VlYzl8wY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer.word_counts"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "V6n5lXrml8wb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocabulary_size = len(tokenizer.word_counts)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cUTxg43El8we",
        "colab_type": "text"
      },
      "source": [
        "### Convert to Numpy Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "lNoF8nMUl8wf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "5NYzee4Al8wi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sequences = np.array(sequences)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "tGV7s1hul8wm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sequences"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_KRI6q_l8wq",
        "colab_type": "text"
      },
      "source": [
        "# Creating an LSTM based model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q366TUQYl8wr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,LSTM,Embedding"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vAWHqNLFl8wv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_model(vocabulary_size, seq_len):\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(vocabulary_size, 25, input_length=seq_len))\n",
        "    model.add(LSTM(150, return_sequences=True))\n",
        "    model.add(LSTM(150))\n",
        "    model.add(Dense(150, activation='relu'))\n",
        "\n",
        "    model.add(Dense(vocabulary_size, activation='softmax'))\n",
        "    \n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "   \n",
        "    model.summary()\n",
        "    \n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ulu4gfNVl8wz",
        "colab_type": "text"
      },
      "source": [
        "### Train / Test Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IiuI1ZTvl8w0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.utils import to_categorical"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kMl7YL0Al8w5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sequences"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "asrv1mIFl8w-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# First 49 words\n",
        "sequences[:,:-1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FyJAEjF2l8xD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# last Word\n",
        "sequences[:,-1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8Mov8Zzl8xH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = sequences[:,:-1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ly8nbxg_l8xL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = sequences[:,-1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MzYpc4Ajl8xO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = to_categorical(y, num_classes=vocabulary_size+1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WhjWOOvkl8xR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seq_len = X.shape[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iIEtblP9l8xU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seq_len"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tlENMx6el8xW",
        "colab_type": "text"
      },
      "source": [
        "### Training the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GX5iS0Eal8xZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define model\n",
        "model = create_model(vocabulary_size+1, seq_len)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQCsnj94l8xc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pickle import dump,load"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UhVwgArrl8xg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# fit model\n",
        "model.fit(X, y, batch_size=128, epochs=300,verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "Yk2xhVmul8xl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# save the model to file\n",
        "model.save('epochBIG.h5')\n",
        "# save the tokenizer\n",
        "dump(tokenizer, open('epochBIG', 'wb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k6JXFX-nl8xp",
        "colab_type": "text"
      },
      "source": [
        "# Generating New Text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ydxlPU0Ll8xp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from random import randint\n",
        "from pickle import load\n",
        "from keras.models import load_model\n",
        "from keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wFrKS5gXl8xt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_text(model, tokenizer, seq_len, seed_text, num_gen_words):\n",
        "    '''\n",
        "    INPUTS:\n",
        "    model : model that was trained on text data\n",
        "    tokenizer : tokenizer that was fit on text data\n",
        "    seq_len : length of training sequence\n",
        "    seed_text : raw string text to serve as the seed\n",
        "    num_gen_words : number of words to be generated by model\n",
        "    '''\n",
        "    \n",
        "    # Final Output\n",
        "    output_text = []\n",
        "    \n",
        "    # Intial Seed Sequence\n",
        "    input_text = seed_text\n",
        "    \n",
        "    # Create num_gen_words\n",
        "    for i in range(num_gen_words):\n",
        "        \n",
        "        # Take the input text string and encode it to a sequence\n",
        "        encoded_text = tokenizer.texts_to_sequences([input_text])[0]\n",
        "        \n",
        "        # Pad sequences to our trained rate (50 words in the video)\n",
        "        pad_encoded = pad_sequences([encoded_text], maxlen=seq_len, truncating='pre')\n",
        "        \n",
        "        # Predict Class Probabilities for each word\n",
        "        pred_word_ind = model.predict_classes(pad_encoded, verbose=0)[0]\n",
        "        \n",
        "        # Grab word\n",
        "        pred_word = tokenizer.index_word[pred_word_ind] \n",
        "        \n",
        "        # Update the sequence of input text (shifting one over with the new word)\n",
        "        input_text += ' ' + pred_word\n",
        "        \n",
        "        output_text.append(pred_word)\n",
        "        \n",
        "    # Make it look like a sentence.\n",
        "    return ' '.join(output_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HiRpG9eJl8xz",
        "colab_type": "text"
      },
      "source": [
        "### Grab a random seed sequence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-y3ZI_Bl8x0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text_sequences[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JYChJWACl8x4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "random.seed(101)\n",
        "random_pick = random.randint(0,len(text_sequences))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rKZg9Fcql8x8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "random_seed_text = text_sequences[random_pick]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqeSskHtl8yA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "random_seed_text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uN08QfUhl8yE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seed_text = ' '.join(random_seed_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dL7EH0C8l8yI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seed_text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l2-Npntjl8yM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "generate_text(model,tokenizer,seq_len,seed_text=seed_text,num_gen_words=50)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qKqS70obl8yQ",
        "colab_type": "text"
      },
      "source": [
        "### Exploring Generated Sequence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFIGGyGMl8yR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "full_text = read_file('moby_dick_four_chapters.txt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "seF3wcSnl8yU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i,word in enumerate(full_text.split()):\n",
        "    if word == 'inkling':\n",
        "        print(' '.join(full_text.split()[i-20:i+20]))\n",
        "        print('\\n')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}